Task,Dataset,Script_file,Hparam_file,Data_prep_file,Readme_file,Result_url,HF_repo,test_debug_flags,test_debug_checks
ASR,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_en_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,
ASR,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_fr_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-fr,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,
ASR,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_it_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,
ASR,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_rw_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,
ASR,CommonVoice,recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py,recipes/CommonVoice/ASR/CTC/hparams/train_de_with_wav2vec.yaml,recipes/CommonVoice/ASR/CTC/common_voice_prepare.py,recipes/CommonVoice/ASR/CTC/README.md,https://drive.google.com/drive/folders/19G2Zm8896QSVDqVfs7PS_W86-K0-5xeC?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-de,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,
ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_de.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-de,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --rnn_neurons=128 --dnn_neurons=128 --dec_neurons=128 --emb_size=64 --cnn_channels=[64, 100, 128]",
ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_en.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --rnn_neurons=128 --dnn_neurons=128 --dec_neurons=128 --emb_size=64 --cnn_channels=[64, 100, 128]",
ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_fr.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-fr,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --rnn_neurons=128 --dnn_neurons=128 --dec_neurons=128 --emb_size=64 --cnn_channels=[64, 100, 128]",
ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_it.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-it,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --rnn_neurons=128 --dnn_neurons=128 --dec_neurons=128 --emb_size=64 --cnn_channels=[64, 100, 128]",
ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_rw.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --rnn_neurons=128 --dnn_neurons=128 --dec_neurons=128 --emb_size=64 --cnn_channels=[64, 100, 128]",
ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_en_with_wav2vec.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-en,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --emb_size=64 --dec_neurons=128 --beam_size=3 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,
ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_fr_with_wav2vec.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --emb_size=64 --dec_neurons=128 --beam_size=3 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,
ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_it_with_wav2vec.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-crdnn-commonvoice-it,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --emb_size=64 --dec_neurons=128 --beam_size=3 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,
ASR,CommonVoice,recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py,recipes/CommonVoice/ASR/seq2seq/hparams/train_rw_with_wav2vec.yaml,recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py,recipes/CommonVoice/ASR/seq2seq/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,https://huggingface.co/speechbrain/asr-wav2vec2-commonvoice-rw,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --number_of_ctc_epochs=1 --skip_prep=True --output_neurons=27 --dnn_neurons=128 --emb_size=64 --dec_neurons=128 --beam_size=3 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,
ASR,CommonVoice,recipes/CommonVoice/ASR/transducer/train.py,recipes/CommonVoice/ASR/transducer/hparams/train_fr.yaml,recipes/CommonVoice/ASR/transducer/common_voice_prepare.py,recipes/CommonVoice/ASR/transducer/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,"--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --rnn_neurons=64 --dnn_neurons=64 --dec_neurons=64 --joint_dim=64 --cnn_channels=[64, 100, 128]",
ASR,CommonVoice,recipes/CommonVoice/ASR/transformer/train.py,recipes/CommonVoice/ASR/transformer/hparams/train_fr.yaml,recipes/CommonVoice/ASR/transformer/common_voice_prepare.py,recipes/CommonVoice/ASR/transformer/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --output_neurons=27 --d_model=128 --num_encoder_layers=3 --num_decoder_layers=3 --d_ffn=256 --stage_one_epochs=1,
ASR,CommonVoice,recipes/CommonVoice/ASR/transformer/train_with_whisper.py,recipes/CommonVoice/ASR/transformer/hparams/train_ar_hf_whisper.yaml,recipes/CommonVoice/ASR/transformer/common_voice_prepare.py,recipes/CommonVoice/ASR/transformer/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=1 --skip_prep=True,
ASR,CommonVoice,recipes/CommonVoice/ASR/transformer/train_with_whisper.py,recipes/CommonVoice/ASR/transformer/hparams/train_fa_hf_whisper.yaml,recipes/CommonVoice/ASR/transformer/common_voice_prepare.py,recipes/CommonVoice/ASR/transformer/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=1 --skip_prep=True,
ASR,CommonVoice,recipes/CommonVoice/ASR/transformer/train_with_whisper.py,recipes/CommonVoice/ASR/transformer/hparams/train_fr_hf_whisper.yaml,recipes/CommonVoice/ASR/transformer/common_voice_prepare.py,recipes/CommonVoice/ASR/transformer/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=1 --skip_prep=True,
ASR,CommonVoice,recipes/CommonVoice/ASR/transformer/train_with_whisper.py,recipes/CommonVoice/ASR/transformer/hparams/train_sr_hf_whisper.yaml,recipes/CommonVoice/ASR/transformer/common_voice_prepare.py,recipes/CommonVoice/ASR/transformer/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=1 --skip_prep=True,
ASR,CommonVoice,recipes/CommonVoice/ASR/transformer/train_with_whisper.py,recipes/CommonVoice/ASR/transformer/hparams/train_mn_hf_whisper.yaml,recipes/CommonVoice/ASR/transformer/common_voice_prepare.py,recipes/CommonVoice/ASR/transformer/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=1 --skip_prep=True,
ASR,CommonVoice,recipes/CommonVoice/ASR/transformer/train_with_whisper.py,recipes/CommonVoice/ASR/transformer/hparams/train_hi_hf_whisper.yaml,recipes/CommonVoice/ASR/transformer/common_voice_prepare.py,recipes/CommonVoice/ASR/transformer/README.md,https://drive.google.com/drive/folders/11NMzY0zV-NqJmPMyZfC3RtT64bYe-G_O?usp=sharing,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=1 --skip_prep=True,
SSL,CommonVoice,recipes/CommonVoice/self-supervised-learning/wav2vec2/train_hf_wav2vec2.py,recipes/CommonVoice/self-supervised-learning/wav2vec2/hparams/wav2vec2_base.yaml,recipes/CommonVoice/self-supervised-learning/wav2vec2/common_voice_prepare.py,recipes/CommonVoice/self-supervised-learning/wav2vec2/README.md,,,--data_folder=tests/samples/ASR/ --train_csv=tests/samples/annotation/ASR_train.csv --valid_csv=tests/samples/annotation/ASR_train.csv --test_csv=tests/samples/annotation/ASR_train.csv --number_of_epochs=2 --skip_prep=True --d_model=128 --wav2vec2_folder=tests/tmp/wav2vec2_checkpoint,
